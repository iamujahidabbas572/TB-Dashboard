{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for tb_2022-09-30.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset\n",
    "tb_data = pd.read_csv('tb_2022-09-30.csv')\n",
    "\n",
    "# Step 1: Drop columns with more than 50% missing values\n",
    "tb_data_cleaned = tb_data.dropna(thresh=tb_data.shape[0] * 0.5, axis=1)\n",
    "\n",
    "# Step 2: Remove rows with missing critical values\n",
    "tb_data_cleaned = tb_data_cleaned.dropna(subset=['iso3', 'country', 'year'])\n",
    "\n",
    "# Step 3: Fill missing numeric values with interpolation (time-based for years)\n",
    "numeric_columns = tb_data_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Interpolate missing values within each group (country)\n",
    "tb_data_cleaned[numeric_columns] = tb_data_cleaned.groupby('country')[numeric_columns]\\\n",
    "    .apply(lambda group: group.interpolate()).reset_index(drop=True)\n",
    "\n",
    "# Handle zero values in numeric columns by replacing them with the column mean\n",
    "for col in numeric_columns:\n",
    "    col_mean = tb_data_cleaned[col].mean()  # Calculate the mean of the column\n",
    "    tb_data_cleaned[col] = tb_data_cleaned[col].replace(0, col_mean)  # Replace zeros with the column mean\n",
    "\n",
    "# Step 4: Normalize metrics (e.g., TB cases per 100,000 people)\n",
    "tb_data_cleaned['tb_cases_per_100k'] = tb_data_cleaned['newinc'] / tb_data_cleaned['pop'] * 100000\n",
    "\n",
    "# Save the preprocessed file\n",
    "tb_data_cleaned.to_csv('tb_preprocessfile_1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['iso3', 'year', 'country', 'iso2', 'iso.numeric', 'g.whoregion',\n",
       "       'new.ep', 'tot.newrel', 'c.newunk', 'c.newinc', 'c.ret', 'c.notified',\n",
       "       'c.new.014', 'e.pop.m04', 'e.pop.m514', 'e.pop.m014', 'e.pop.m1524',\n",
       "       'e.pop.m2534', 'e.pop.m3544', 'e.pop.m4554', 'e.pop.m5564', 'e.pop.m65',\n",
       "       'e.pop.m15plus', 'e.pop.f04', 'e.pop.f514', 'e.pop.f014', 'e.pop.f1524',\n",
       "       'e.pop.f2534', 'e.pop.f3544', 'e.pop.f4554', 'e.pop.f5564', 'e.pop.f65',\n",
       "       'e.pop.f15plus', 'e.pop.15plus', 'e.pop.num', 'pop', 'newinc',\n",
       "       'c.new.tsr', 'ch', 'conf', 'ep', 'tb_cases_per_100k'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_data_cleaned.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "file tx_2022-08-29.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "tx_data = pd.read_csv('tx_2022-08-29.csv')\n",
    "\n",
    "\n",
    "# Step 1: Drop columns with more than 50% missing values\n",
    "tx_data_cleaned = tx_data.dropna(thresh=tx_data.shape[0] * 0.5, axis=1)\n",
    "\n",
    "\n",
    "# Step 2: Remove rows with missing critical values\n",
    "tx_data_cleaned = tx_data_cleaned.dropna(subset=['country', 'iso3', 'year'])\n",
    "\n",
    "# Step 3: Fill missing numeric values with the median or by grouping\n",
    "numeric_columns = tx_data_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "tx_data_cleaned[numeric_columns] = tx_data_cleaned[numeric_columns].fillna(tx_data_cleaned[numeric_columns].median())\n",
    "\n",
    "# Step 4: Save the preprocessed file\n",
    "tx_data_cleaned.to_csv('tb_preprocessfile_2.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'year', 'iso2', 'iso3', 'iso.numeric', 'g.whoregion',\n",
       "       'rep.meth', 'new.sp.coh', 'new.sp.cur', 'new.sp.cmplt', 'new.sp.died',\n",
       "       'new.sp.def', 'c.new.sp.neval', 'c.new.sp.tsr', 'c.tsr', 'c.ret.tsr',\n",
       "       'c.new.tsr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_data_cleaned.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
